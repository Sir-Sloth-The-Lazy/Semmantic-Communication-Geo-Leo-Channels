{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SemViT vs. BPG Comparison (Colab Ready)\n",
    "\n",
    "This notebook generates a performance comparison chart between:\n",
    "1.  **Your Trained SemViT Models** (Mixed, LEO, GEO, AWGN)\n",
    "2.  **BPG + Capacity** (Theoretical Upper Bound for BPG)\n",
    "3.  **BPG + LDPC** (Simulated Adaptive BPG Performance)\n",
    "\n",
    "### Instructions\n",
    "1.  **Run Setup**: Run the first code cell to install dependencies (`sionna`, `tensorflow-compression`, etc.).\n",
    "2.  **Upload Repository**: Ensure the `models/` and `utils/` folders from the repo are present.\n",
    "3.  **Upload Weights**: Upload your trained model weights to a `weights/` folder (or update the paths below).\n",
    "4.  **Run All Cells**: The notebook will evaluate your models and plot them against the hardcoded BPG baselines.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccc226e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- SETUP: Install Dependencies ---\n",
    "\n",
    "# IF YOU CLONED THE REPO: Un-comment the next line to install strict versions from requirements.txt\n",
    "# !pip install -r requirements.txt\n",
    "\n",
    "# OTHERWISE: Run this to install critical libraries (Relaxed versions for Colab compatibility)\n",
    "!pip install sionna==0.14.0 tensorflow-compression tensorflow-addons mitsuba==3.2.1\n",
    "\n",
    "# Note: If 'tensorflow-compression' fails to install, the code handles it gracefully (using standard layers).\n",
    "# You can ignore the error if you see \"No matching distribution found\".\n",
    "\n",
    "# --- AUTO-NAVIGATION ---\n",
    "# If you cloned the repo, we'll try to enter the directory automatically.\n",
    "import os\n",
    "repo_name = 'Semmantic-Communication-Geo-Leo-Channels' # Adjust if your folder name differs\n",
    "if os.path.exists(repo_name):\n",
    "    os.chdir(repo_name)\n",
    "    print(f\"Changed directory to {os.getcwd()}\")\n",
    "elif os.path.exists('/content/' + repo_name):\n",
    "    os.chdir('/content/' + repo_name)\n",
    "    print(f\"Changed directory to {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure we can import from the repo structure\n",
    "import sys\n",
    "if not os.path.exists('models'):\n",
    "    print(\"WARNING: 'models' directory not found. Please clone the repo or upload files.\")\n",
    "\n",
    "from models.model import SemViT\n",
    "from utils.datasets import dataset_generator\n",
    "\n",
    "# Disable eager execution for performance if needed, though Keras 3 might prefer it.\n",
    "# For this repo's TF version (likely <2.16 given the code style), disabling might be safer for loops.\n",
    "tf.config.run_functions_eagerly(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CONFIGURATION ---\n",
    "\n",
    "# 1. Test Conditions\n",
    "SNR_RANGE = [0, 2, 5, 7, 10, 12, 15]  # The SNRs we have BPG data for\n",
    "TEST_CHANNEL = 'AWGN'                 # Channel to test User Models on\n",
    "DATA_SIZE = 512                       # 1/6 Bandwidth Ratio (512 / 32*32*3)\n",
    "\n",
    "# 2. User Models to Evaluate\n",
    "# UPDATE THESE PATHS to match where you uploaded your files in Colab\n",
    "MODELS_TO_TEST = {\n",
    "    \"Mixed (LEO+GEO)\": \"weights/experiment_mixed_sat_138.weights.h5\",\n",
    "    \"LEO Only\":        \"weights/experiment_leo_sat_128.weights.h5\",\n",
    "    \"GEO Only\":        \"weights/experiment_geo_sat_34.weights.h5\",\n",
    "    \"AWGN (Baseline)\": \"weights/CCVVCC_512_10dB_599.weights.h5\"\n",
    "}\n",
    "\n",
    "# 3. BPG Baselines (Extracted from bpg-ldpc.ipynb)\n",
    "# Bandwidth Ratio = 1/6\n",
    "\n",
    "# Theoretical Limit: BPG compressed to Channel Capacity size\n",
    "BPG_CAPACITY_DATA = {\n",
    "    \"PSNR\": [24.13, 25.65, 28.24, 29.72, 31.59, 32.83, 34.54],\n",
    "    \"SSIM\": [0.82,  0.87,  0.92,  0.94,  0.96,  0.97,  0.98]\n",
    "}\n",
    "\n",
    "# Practical Baseline: BPG + LDPC (Adaptive Modulation/Coding)\n",
    "# Best performing MCS chosen for each SNR from the simulation logs\n",
    "BPG_LDPC_DATA = {\n",
    "    \"PSNR\": [21.66, 24.13, 25.43, 27.86, 29.73, 30.49, 32.83],\n",
    "    \"SSIM\": [0.72,  0.82,  0.86,  0.92,  0.94,  0.95,  0.97]\n",
    "}\n",
    "\n",
    "# 4. Model Architecture (Must match training)\n",
    "BLOCK_TYPES = ['C', 'C', 'V', 'V', 'C', 'C']\n",
    "FILTERS = [256, 256, 256, 256, 256, 256]\n",
    "NUM_BLOCKS = [1, 1, 3, 3, 1, 1]\n",
    "HAS_GDN = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- DATASET LOADER ---\n",
    "print(\"Preparing Dataset...\")\n",
    "def normalize_img(x, y):\n",
    "    return (tf.cast(x, tf.float32) / 255.0, tf.cast(x, tf.float32) / 255.0)\n",
    "\n",
    "# Tries to load CIFAR-10. If not found, it downloads it.\n",
    "try:\n",
    "    test_ds_raw = dataset_generator('./dataset/CIFAR10/test/', shuffle=False)\n",
    "except:\n",
    "    print(\"Dataset not found locally. Downloading CIFAR-10...\")\n",
    "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "    # Create a tf.data.Dataset from the numpy arrays\n",
    "    test_ds_raw = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "    test_ds_raw = test_ds_raw.batch(1) # generator usually returns batched\n",
    "\n",
    "# Take a subset for quicker evaluation (e.g., 200 images)\n",
    "# Remove .take(200) to evaluate on the whole set (slower)\n",
    "test_ds = test_ds_raw.map(normalize_img).take(200).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- EVALUATION FUNCTION ---\n",
    "def evaluate_model(weights_path, snr_db):\n",
    "    print(f\"  Loading {weights_path} for SNR {snr_db}dB...\")\n",
    "    \n",
    "    # Initialize Model\n",
    "    model = SemViT(\n",
    "        block_types=BLOCK_TYPES,\n",
    "        filters=FILTERS,\n",
    "        num_blocks=NUM_BLOCKS,\n",
    "        has_gdn=HAS_GDN,\n",
    "        num_symbols=DATA_SIZE,\n",
    "        snrdB=snr_db,\n",
    "        channel=TEST_CHANNEL \n",
    "    )\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    # Build passing dummy input\n",
    "    model(tf.zeros((1, 32, 32, 3))) \n",
    "    \n",
    "    # Load Weights\n",
    "    if not os.path.exists(weights_path):\n",
    "        print(f\"    [ERROR] File not found: {weights_path}\")\n",
    "        return None, None\n",
    "    \n",
    "    try:\n",
    "        model.load_weights(weights_path, skip_mismatch=True)\n",
    "    except Exception as e:\n",
    "        print(f\"    [ERROR] Failed to load weights: {e}\")\n",
    "        return None, None\n",
    "\n",
    "    # Run Inference\n",
    "    psnr_sum = 0.0\n",
    "    ssim_sum = 0.0\n",
    "    count = 0\n",
    "    \n",
    "    for x, y in test_ds:\n",
    "        recon = model(x, training=False)\n",
    "        # Calculate Metrics\n",
    "        batch_psnr = tf.reduce_mean(tf.image.psnr(x, recon, max_val=1.0))\n",
    "        batch_ssim = tf.reduce_mean(tf.image.ssim(x, recon, max_val=1.0))\n",
    "        \n",
    "        psnr_sum += float(batch_psnr)\n",
    "        ssim_sum += float(batch_ssim)\n",
    "        count += 1\n",
    "    \n",
    "    tf.keras.backend.clear_session()\n",
    "    return (psnr_sum / count), (ssim_sum / count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- MAIN LOOP ---\n",
    "results = {name: {\"PSNR\": [], \"SSIM\": []} for name in MODELS_TO_TEST}\n",
    "\n",
    "for model_name, path in MODELS_TO_TEST.items():\n",
    "    print(f\"Evaluating {model_name}...\")\n",
    "    current_snr_psnr = []\n",
    "    current_snr_ssim = []\n",
    "    \n",
    "    for snr in SNR_RANGE:\n",
    "        p, s = evaluate_model(path, snr)\n",
    "        if p is None: \n",
    "            p, s = 0.0, 0.0 # Handle missing weights gracefully for plot\n",
    "        current_snr_psnr.append(p)\n",
    "        current_snr_ssim.append(s)\n",
    "        print(f\"    SNR={snr}: PSNR={p:.2f}, SSIM={s:.3f}\")\n",
    "    \n",
    "    results[model_name][\"PSNR\"] = current_snr_psnr\n",
    "    results[model_name][\"SSIM\"] = current_snr_ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- PLOTTING ---\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 7))\n",
    "\n",
    "# Colors for User Models\n",
    "colors = ['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple']\n",
    "\n",
    "# 1. PSNR Plot\n",
    "ax = axes[0]\n",
    "# -- Baselines --\n",
    "ax.plot(SNR_RANGE, BPG_CAPACITY_DATA[\"PSNR\"], label=\"BPG + Capacity\", \n",
    "        color='black', linestyle='--', linewidth=2, marker='^')\n",
    "ax.plot(SNR_RANGE, BPG_LDPC_DATA[\"PSNR\"], label=\"BPG + LDPC\", \n",
    "        color='gray', linestyle='-.', linewidth=2, marker='v')\n",
    "# -- User Models --\n",
    "for i, (name, metrics) in enumerate(results.items()):\n",
    "    ax.plot(SNR_RANGE, metrics[\"PSNR\"], label=name, marker='o', linewidth=2.5, color=colors[i % len(colors)])\n",
    "\n",
    "ax.set_title(\"PSNR Comparison\", fontsize=14)\n",
    "ax.set_xlabel(\"SNR (dB)\", fontsize=12)\n",
    "ax.set_ylabel(\"PSNR (dB)\", fontsize=12)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend(fontsize=10)\n",
    "\n",
    "# 2. SSIM Plot\n",
    "ax = axes[1]\n",
    "# -- Baselines --\n",
    "ax.plot(SNR_RANGE, BPG_CAPACITY_DATA[\"SSIM\"], label=\"BPG + Capacity\", \n",
    "        color='black', linestyle='--', linewidth=2, marker='^')\n",
    "ax.plot(SNR_RANGE, BPG_LDPC_DATA[\"SSIM\"], label=\"BPG + LDPC\", \n",
    "        color='gray', linestyle='-.', linewidth=2, marker='v')\n",
    "# -- User Models --\n",
    "for i, (name, metrics) in enumerate(results.items()):\n",
    "    ax.plot(SNR_RANGE, metrics[\"SSIM\"], label=name, marker='o', linewidth=2.5, color=colors[i % len(colors)])\n",
    "\n",
    "ax.set_title(\"SSIM Comparison\", fontsize=14)\n",
    "ax.set_xlabel(\"SNR (dB)\", fontsize=12)\n",
    "ax.set_ylabel(\"SSIM\", fontsize=12)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend(fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"colab_comparison_chart.png\", dpi=300)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
