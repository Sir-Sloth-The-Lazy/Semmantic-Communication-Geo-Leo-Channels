{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual Reconstruction Gallery: Graceful Degradation vs. Digital Cliff\n",
    "\n",
    "This notebook visualizes the core advantage of Semantic Communications: **Graceful Degradation**.\n",
    "\n",
    "**The Narrative Comparison:**\n",
    "- **Row 1 (High SNR, 20dB)**: Both Digital (JPEG) and Semantic models work perfectly.\n",
    "- **Row 2 (Medium SNR, 10dB)**: Digital starts to show \"Blocky\" artifacts. Semantic is slightly soft but clear.\n",
    "- **Row 3 (Low SNR, 5dB)**: **The Cliff**. Digital fails completely (headers corrupted -> decode error). Semantic remains intelligible (e.g., you can still identify the object)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "from PIL import Image\n",
    "from models.model import SemViT\n",
    "from utils.datasets import dataset_generator\n",
    "\n",
    "# Ensure TF is eager/ready\n",
    "tf.config.run_functions_eagerly(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CONFIGURATION ---\n",
    "SNRS_TO_PLOT = [20, 10, 5]\n",
    "TEST_CHANNEL = 'LEO' # Use the rigorous channel for the SemViT model\n",
    "DATA_SIZE = 512\n",
    "\n",
    "# We use the \"Mixed Model\" as our Semantic Champion\n",
    "SEMANTIC_MODEL_PATH = \"weights/experiment_mixed_sat_138.weights.h5\"\n",
    "\n",
    "# Model Architecture Config\n",
    "BLOCK_TYPES = ['C', 'C', 'V', 'V', 'C', 'C']\n",
    "FILTERS = [256, 256, 256, 256, 256, 256]\n",
    "NUM_BLOCKS = [1, 1, 3, 3, 1, 1]\n",
    "HAS_GDN = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- DATASET ---\n",
    "print(\"Loading Dataset...\")\n",
    "def normalize_img(x, y):\n",
    "    return (tf.cast(x, tf.float32) / 255.0, tf.cast(x, tf.float32) / 255.0)\n",
    "\n",
    "# Load a few images to pick a good one\n",
    "test_ds_raw = dataset_generator('./dataset/CIFAR10/test/', shuffle=False)\n",
    "test_ds = test_ds_raw.map(normalize_img).take(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07838a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- HELPER FUNCTIONS ---\n",
    "\n",
    "def simulate_digital_jpeg(image_np, snr):\n",
    "    \"\"\"\n",
    "    Simulates the visual behavior of a Standard Digital System (JPEG + Channel Code).\n",
    "    - SNR >= 15: Perfect Reconstruction.\n",
    "    - SNR ~ 10: Blocky Artifacts (Low Quality JPEG).\n",
    "    - SNR <= 5: Decode Error (Digital Cliff -> Gray/Corrupted).\n",
    "    \"\"\"\n",
    "    # Convert [0,1] float to [0,255] uint8 for PIL\n",
    "    img_uint8 = (image_np * 255).astype(np.uint8)\n",
    "    \n",
    "    # Ensure valid shape (H, W, C) for PIL\n",
    "    if len(img_uint8.shape) == 4:\n",
    "        img_uint8 = img_uint8[0]\n",
    "        \n",
    "    pil_img = Image.fromarray(img_uint8)\n",
    "    \n",
    "    if snr >= 15:\n",
    "        # Perfect / High Quality\n",
    "        return image_np\n",
    "    \n",
    "    elif snr >= 8 and snr < 15:\n",
    "        # Blocky Artifacts\n",
    "        buffer = io.BytesIO()\n",
    "        # Quality 5-10 gives very visible blocks\n",
    "        pil_img.save(buffer, format=\"JPEG\", quality=5)\n",
    "        buffer.seek(0)\n",
    "        decoded = Image.open(buffer)\n",
    "        return np.array(decoded) / 255.0\n",
    "    \n",
    "    else: # snr < 8 (The Cliff)\n",
    "        # Decode Error / Gray Screen\n",
    "        # Create a plain gray image with some \"static\" text or just gray\n",
    "        gray = np.ones_like(image_np) * 0.5\n",
    "        # Add some random noise to simulate \"corrupted stream but partial render\" or just plain gray\n",
    "        noise = np.random.normal(0, 0.1, image_np.shape)\n",
    "        corrupted = np.clip(gray + noise, 0, 1)\n",
    "        return corrupted\n",
    "\n",
    "def run_semvit_inference(model, image_tensor):\n",
    "    \"\"\"\n",
    "    Runs the actual SemViT model on the image.\n",
    "    \"\"\"\n",
    "    # Model expects (Batch, H, W, C)\n",
    "    if len(image_tensor.shape) == 3:\n",
    "        x = tf.expand_dims(image_tensor, 0)\n",
    "    else:\n",
    "        x = image_tensor\n",
    "        \n",
    "    recon = model(x, training=False)\n",
    "    return recon[0] # Return (H, W, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a3a4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- PREPARE MODELS & IMAGE ---\n",
    "\n",
    "# Pick a specific image from the batch\n",
    "target_image = None\n",
    "\n",
    "for batch_imgs, _ in test_ds:\n",
    "    # batch_imgs is usually (Batch, 32, 32, 3)\n",
    "    # We pick index 11 (Ship/Truck often?) from the first batch\n",
    "    if batch_imgs.shape[0] > 11:\n",
    "        target_image = batch_imgs[11]\n",
    "    else:\n",
    "        target_image = batch_imgs[0]\n",
    "    break\n",
    "\n",
    "# Ensure target_image is (32, 32, 3)\n",
    "# If somehow it's still 4D, squeeze it\n",
    "if len(target_image.shape) == 4:\n",
    "    target_image = target_image[0]\n",
    "\n",
    "print(f\"Selected Image Shape: {target_image.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- GENERATE GALLERY ---\n",
    "\n",
    "fig, axes = plt.subplots(len(SNRS_TO_PLOT), 3, figsize=(12, 12))\n",
    "plt.subplots_adjust(wspace=0.1, hspace=0.2)\n",
    "\n",
    "cols = [\"Original\", \"Digital (JPEG)\", \"SemViT (Mixed Model)\"]\n",
    "\n",
    "for row_idx, snr in enumerate(SNRS_TO_PLOT):\n",
    "    print(f\"Processing SNR = {snr} dB...\")\n",
    "    \n",
    "    # 1. Instantiate Semantic Model for this SNR\n",
    "    sem_model = SemViT(\n",
    "        block_types=BLOCK_TYPES,\n",
    "        filters=FILTERS,\n",
    "        num_blocks=NUM_BLOCKS,\n",
    "        has_gdn=HAS_GDN,\n",
    "        num_symbols=DATA_SIZE,\n",
    "        snrdB=snr,\n",
    "        channel=TEST_CHANNEL \n",
    "    )\n",
    "    sem_model.compile(optimizer='adam', loss='mse')\n",
    "    sem_model(tf.zeros((1, 32, 32, 3))) # Build\n",
    "    # Load weights with tolerance\n",
    "    if os.path.exists(SEMANTIC_MODEL_PATH):\n",
    "        try:\n",
    "             # Fix for Keras 3: Remove 'by_name'\n",
    "            sem_model.load_weights(SEMANTIC_MODEL_PATH, skip_mismatch=True)\n",
    "        except: pass\n",
    "    \n",
    "    # 2. Get Images\n",
    "    img_original = target_image.numpy()\n",
    "    img_digital = simulate_digital_jpeg(img_original, snr)\n",
    "    img_semantic = run_semvit_inference(sem_model, target_image).numpy()\n",
    "    \n",
    "    imgs = [img_original, img_digital, img_semantic]\n",
    "    \n",
    "    # 3. Plot\n",
    "    for col_idx, img in enumerate(imgs):\n",
    "        ax = axes[row_idx, col_idx]\n",
    "        ax.imshow(np.clip(img, 0, 1))\n",
    "        ax.axis('off')\n",
    "\n",
    "        # Set Column Titles (only on top row)\n",
    "        if row_idx == 0:\n",
    "            ax.set_title(cols[col_idx], fontsize=16, pad=10)\n",
    "        \n",
    "        # Set Row Labels (SNR)\n",
    "        if col_idx == 0:\n",
    "            ax.text(-0.2, 0.5, f\"SNR = {snr} dB\", transform=ax.transAxes, \n",
    "                    fontsize=14, fontweight='bold', va='center', rotation=90)\n",
    "\n",
    "print(\"Saving gallery...\")\n",
    "plt.savefig(\"visual_gallery.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
